{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import cv2\n",
    "import imghdr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Activation, Flatten, Dropout, Dense\n",
    "# from keras.layers.core import Flatten\n",
    "# from keras.layers.core import Dropout\n",
    "# from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "# from keras.layers.convolutional import Conv2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "# from keras.layers.convolutional import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "# cwd = os.getcwd()\n",
    "# os.chdir(cwd)\n",
    "#data_dir=r\"C:\\Users\\HP\\Desktop\\Online Courses\\IBM Machine Learning Engineer\\4. Deep Learning and Reinforcement Learning\\Week 9\\projects\\nemophea\\origional data\\chest_xray\\chest_xray\"\n",
    "data_dir=r\"C:\\Users\\BAYEE\\Desktop\\Online Courses\\IBM Machine Learning Engineer\\4. Deep Learning and Reinforcement Learning\\Week 9\\projects\\nemophea\\origional data\\chest_xray\\chest_xray\"\n",
    "#print(os.listdir(r\"C:\\Users\\HP\\Desktop\\Online Courses\\IBM Machine Learning Engineer\\4. Deep Learning and Reinforcement Learning\\Week 9\\projects\\nemophea\\origional data\\chest_xray\"))\n",
    "os.listdir(os.path.join(data_dir, 'test'))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_exts = ['jpeg','jpg', 'bmp', 'png']\n",
    "\n",
    "trainNormal = []\n",
    "for i in os.listdir(os.path.join(data_dir, 'train', 'NORMAL')):\n",
    "    i = os.path.join(data_dir, 'train', 'NORMAL', i)\n",
    "    tip = imghdr.what(i)\n",
    "    if tip in image_exts: \n",
    "        trainNormal.append(i)\n",
    "        \n",
    "trainPneumonia = []\n",
    "for i in os.listdir(os.path.join(data_dir, 'train', 'PNEUMONIA')):\n",
    "    i = os.path.join(data_dir, 'train', 'PNEUMONIA', i)\n",
    "    tip = imghdr.what(i)\n",
    "    if tip in image_exts: \n",
    "        trainPneumonia.append(i)\n",
    "        \n",
    "testNormal = []\n",
    "for i in os.listdir(os.path.join(data_dir, 'test', 'NORMAL')):\n",
    "    i = os.path.join(data_dir, 'test', 'NORMAL', i)\n",
    "    tip = imghdr.what(i)\n",
    "    if tip in image_exts: \n",
    "        testNormal.append(i)\n",
    "        \n",
    "testPneumonia = []\n",
    "for i in os.listdir(os.path.join(data_dir, 'test', 'PNEUMONIA')):\n",
    "    i = os.path.join(data_dir, 'test', 'PNEUMONIA', i)\n",
    "    tip = imghdr.what(i)\n",
    "    if tip in image_exts: \n",
    "        testPneumonia.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pneumonia, Normal, All = [], [], []\n",
    "\n",
    "for i, j in zip(trainPneumonia, trainNormal):\n",
    "    Pneumonia.append(i)\n",
    "    Normal.append(j)\n",
    "    All.append(i)\n",
    "    All.append(j)\n",
    "\n",
    "for i, j in zip(testPneumonia, testNormal):\n",
    "    Pneumonia.append(i)\n",
    "    Normal.append(j)\n",
    "    All.append(i)\n",
    "    All.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading images...\")\n",
    "# imagePaths = list(paths.list_images('dataset'))\n",
    "imagePaths = All\n",
    "# print(imagePaths)\n",
    "print(\"Loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    # Extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "    # load the image, and resize it to be a fixed 100x100 pixels, ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (100, 100))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Converting data into Numpy Array, scaling it to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "# # Reshaping for channel dimension\n",
    "data = data.reshape((data.shape[0], data.shape[1], data.shape[2], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Labels\n",
    "LE = LabelEncoder()\n",
    "labels = LE.fit_transform(labels)\n",
    "\n",
    "# One-hot Encoding\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, stratify=labels, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(255,255,3)))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "# model.add(MaxPooling2D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(255, activation='relu'))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "# model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5)) # DROPOUT\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=1e-4), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "ConvNet = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=32, epochs=epochs, verbose=1)\n",
    "print(\"Training Complete\")\n",
    "\n",
    "# from keras.models import load_model\n",
    "\n",
    "# model.save('myModel.h5')\n",
    "# print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('myModel.h5')\n",
    "print(\"Evaluating the network\")\n",
    "predictions = model.predict(X_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=LE.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kneumonia(image):\n",
    "    img = cv2.imread(image)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    resize = tf.image.resize(img, (256,256))\n",
    "    yhat = model.predict(np.expand_dims(resize/255, 0))\n",
    "    if yhat > 0.5: \n",
    "        print(f'Predicted Results : Kneumonia')\n",
    "    else:\n",
    "        print(f'Predicted Results : Normal')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
